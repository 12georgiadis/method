## Post-Photography

On the photographic image after generative AI.

---

For almost two centuries, the photograph had one distinguishing property: it was made by light hitting a surface. Regardless of all the manipulation, staging, and editing that could follow, at the origin was a physical event. Photons bounced off something real, passed through a lens, and left a trace. This is what separated photography from painting, drawing, and every other form of image-making.

Generative AI produces images with no such origin. Nothing was in front of a lens. No light was involved. The image is synthesized from statistical patterns. And yet these images can be indistinguishable from photographs.

This is the post-photographic condition: not that photography is dead, but that the photograph is no longer the only kind of image that looks like a photograph.

---

### Flusser saw this coming

Vilem Flusser, writing in the 1980s, argued that photographs are not windows onto reality but products of an apparatus. The camera is a program, the photographer operates within the program's possibilities, and the resulting image is a "technical image" -- an image produced by a device whose internal workings the operator doesn't fully understand.

Flusser's insight applies even more forcefully to AI-generated images. The diffusion model is an apparatus. The user operates within its possibilities (the prompt, the parameters, the model's training). The resulting image is a technical image in Flusser's precise sense: produced by a system whose internal operations are opaque even to its creators. The 800 million parameters of a diffusion model are not interpretable. Nobody knows why a specific combination of weights produces a specific image. The apparatus has exceeded human understanding of its own mechanism.

What Flusser couldn't anticipate is that the apparatus would no longer need the world as input. His apparatus still required something in front of the lens. The AI apparatus requires only a text prompt -- or another image, or noise. The world is optional.

---

### Two responses

There are two productive responses to the post-photographic condition. They're not contradictory.

**Double down on capture.** If AI can generate any image, then the captured image -- the image that required someone to be somewhere, to point a camera at something, to press the shutter at a specific moment -- gains value precisely because of its origin. Not aesthetic value (AI can match or exceed the aesthetic quality of any photograph) but evidentiary value, experiential value, the value of having-been-there.

This is why I shoot on hacked cameras with open-source firmware, in RAW formats that preserve every bit of data the sensor captures. The commitment to the captured image is not nostalgic -- it's strategic. In a world where any image can be generated, the images that were actually captured become more precious, not less. The grain, the noise, the optical imperfections, the sensor-specific characteristics of a Magic Lantern RAW file are not flaws. They're proof of origin. (This is the practice documented in [open-source-cinema](https://github.com/12georgiadis/open-source-cinema).)

**Embrace the synthesis.** If AI can generate any image, then the generated image becomes a new material -- not a replacement for photography but an addition to the image-maker's palette. The synthesized image has its own properties: it carries the traces of its training data, the biases of its model, the artifacts of its generation process. These properties are not photographic (they don't come from light) but they are material (they come from somewhere and bear the marks of their production).

My practice does both. I capture images with cameras and I generate images with models. I hybridize the two. The resulting images are post-photographic: they don't claim to be pure captures or pure syntheses. They're composites whose power comes from the tension between the traced and the generated, between the indexical and the statistical.

---

### The end of the decisive moment

Cartier-Bresson's "decisive moment" -- the idea that photography's essence is capturing a unique instant -- assumed scarcity. There was one moment, one frame, one chance. The photographer's skill was being ready.

AI eliminates this scarcity entirely. You can generate any moment, any configuration of light and bodies, any scene that ever existed or could exist. The decisive moment becomes irrelevant when every moment is available on demand.

But something is lost in that availability. The generated image of a street scene in 1950s Paris has no contingency -- no accidental passerby, no unplanned shadow, no imperfection of timing. It has the appearance of a moment without the reality of one. It's a statistically plausible moment, not a lived one.

Post-photography navigates this loss. The captured image retains contingency. The generated image offers infinite possibility. The hybrid image -- a captured image processed through a generative model -- holds both: the contingency of what was actually there, reconfigured by the statistical possibilities of what could have been. The decisive moment meets the infinite moment.

---

### Fontcuberta and the crisis of truth

Joan Fontcuberta has spent decades making photographs that look documentary but are entirely fabricated -- fake scientific discoveries, invented landscapes, simulated historical events. His work anticipated the post-photographic condition by decades: if the photograph can lie so convincingly, what was its truth-claim ever worth?

AI pushes Fontcuberta's question to its limit. It's no longer a matter of an artist deliberately fabricating images to provoke. It's a matter of infrastructure: the tools for generating convincing photographic images are now available to everyone, at no cost, in seconds. The crisis of photographic truth is no longer theoretical. It's operational.

The response is not to cling to photography's old truth-claim ("this image proves that this happened") but to build new frameworks for understanding what images are and where they come from. This means making the production process visible, declaring the computational origin of generated images, and treating the hybrid image not as a deception but as a new category that requires new reading skills.

---

### Paglen's invisible images

Trevor Paglen's work on machine vision -- images made by machines for machines, never seen by human eyes -- adds another dimension. Most images produced today are not photographs in any traditional sense. They're data points in training sets, features extracted by neural networks, embeddings in high-dimensional spaces. These images have no frame, no resolution, no color in the human sense. They exist in a space that is post-photographic not because they look different from photographs, but because they were never meant to be looked at.

AI-generated images are made from these invisible images. The training data is processed, compressed, encoded into weights that encode visual patterns without storing any single image. The generated output is a reconstruction from this invisible archive. In a sense, every AI image is a photograph of the training data -- not of the world, but of the dataset. It documents the statistical structure of the images that went in.

This is a genuinely new kind of image. Not a photograph (no light, no lens, no moment). Not a painting (no hand, no gesture, no material). Not a collage (no discrete sources). A statistical image: an image whose content is the average of millions of other images, inflected by a text prompt. Post-photography begins with recognizing this image for what it is and learning to work with it on its own terms.

---

[Back to Method](README.md)
