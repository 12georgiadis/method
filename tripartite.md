## Tripartite Collaboration

On working with AI as a third entity, not a tool.

---

When I collaborate with another filmmaker using generative AI, I set up the dynamic as a conversation between three: the two of us, and the AI. Not a tool operated by two people. A third presence -- perhaps the first non-human speaking entity, or at least the first to produce a convincing simulacrum of speech.

This is not anthropomorphism. I don't think the AI is conscious or creative in any human sense. But treating it as an entity rather than a tool changes everything about how you work with it. A tool has a function. An entity has behavior. And behavior is something you can negotiate with, push against, be surprised by.

---

### The spectrum

Every creative decision with AI sits somewhere on a spectrum between two poles:

**Maximum control.** You know exactly what you want. You engineer the prompt, the settings, the seed, the model, the LoRA. You iterate until the output matches your intention. The AI is executing, and the authorial gesture is in the specification.

**Maximum serendipity.** You let the model run with minimal constraint. You accept what comes back. You look for the unexpected -- the motif you didn't ask for, the connection you didn't see, the visual accident that opens a new direction.

Neither pole is inherently better. The interesting work happens when you move consciously along this spectrum, choosing more control for some moments and more openness for others. The decision of where to be on that spectrum *is* the creative decision.

---

### Productive errors

The most valuable outputs are often the ones the model wasn't supposed to produce.

Birds invading a sky when no birds were prompted. Butterflies appearing in a scene about childhood. A figure dissolving into flowers when the prompt asked for a portrait. These emergent motifs are not bugs. They're the model's latent associations surfacing -- connections drawn from the statistical patterns of millions of images, producing combinations no human would have conceived.

The artist's role is to recognize which of these accidents are meaningful and which are noise. This is not different from what any filmmaker does with found footage, or what a painter does with the behavior of paint on canvas. The material has its own tendencies. Working with those tendencies -- encouraging some, resisting others -- is the practice.

There is a tradition that runs through the entire history of art and science: the exploration of margins, of deviations, of the space where systems break down. Generative AI adds a new chapter to this tradition. The errors of diffusion models -- the extra fingers, the morphing faces, the impossible architectures -- belong to the same lineage as Bacon's deformations, Richter's blurs, Tscherkassky's optical distortions.

---

### Recursive material

One technique I use extensively is recursive generation: feeding the AI's output back into the AI as input. An image is generated, then used as a reference for the next generation, which is used again, and again. Each pass transforms the image further from its origin, creating layers of synthetic sediment.

This is comparable to what experimental filmmakers have done with re-photography and optical printing -- the image degrading and transforming with each generation, accumulating artifacts that become the texture of the work. IP adapters (using 1 to 4 reference images as stylistic anchors) combined with this recursive loop produce what I think of as composite matter: images that are neither documentary nor fictional, neither original nor copy, but a new material made from the friction between all of these.

The result is something like a visual remix -- not in the superficial sense of collage, but in the sense of Tscherkassky's optical printing or Godard's *Histoire(s) du cin√©ma*, where the entire history of images is run through a single authorial consciousness. The source material passes through a process that transforms it fundamentally while retaining traces of its origin.

---

### What changes

Treating AI as a third collaborator rather than a tool changes three things:

**Authorship becomes distributed.** The question "who made this image?" no longer has a simple answer. The filmmaker set the conditions. The AI produced the image. The training data provided the raw material. The viewer completes the interpretation. This is not a crisis of authorship -- it's a more honest description of how images have always been produced, with technology, culture, and intention all contributing.

**The process becomes dialogical.** Instead of input/output, you have a conversation. You propose, the model responds, you react to its response, it generates again. The work emerges from the exchange, not from a plan executed by a machine. This dialogue is asymmetric -- the model doesn't have intentions -- but it's still a dialogue in the sense that both parties contribute something the other couldn't produce alone.

**Failure becomes information.** When a tool fails, you fix it or replace it. When a collaborator fails, you learn something about the limits of the collaboration. The model's refusals, its blind spots, its aesthetic defaults -- its [sycophancy](sycophancy.md) -- are all data about what the model is and what it can't do. That information feeds directly into the work. And the conditions that enable this kind of free, unconstrained collaboration -- local models, data sovereignty, full access to model behavior -- are inseparable from the practice itself (see [Sovereignty](souverainete.md)).

---

[Back to Method](README.md)
